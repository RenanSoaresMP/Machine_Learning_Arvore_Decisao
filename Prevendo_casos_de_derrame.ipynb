{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predição da ocorrência de derrame cerebral em pacinetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializando o Spark\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"SPARK_HOME\"] = \"C:\\Spark\\spark-3.1.3-bin-hadoop2.7\"\n",
    "\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.1.3'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criando a sessão Spark\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Spark entry point\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Desafio - Cientista de Dados - Apache Spark\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- 0: integer (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- age: double (nullable = true)\n",
      " |-- hypertension: integer (nullable = true)\n",
      " |-- heart_disease: integer (nullable = true)\n",
      " |-- ever_married: string (nullable = true)\n",
      " |-- work_type: string (nullable = true)\n",
      " |-- Residence_type: string (nullable = true)\n",
      " |-- avg_glucose_level: double (nullable = true)\n",
      " |-- bmi: double (nullable = true)\n",
      " |-- smoking_status: string (nullable = true)\n",
      " |-- stroke: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Carregando a planilha CSV\n",
    "stroke_df = spark.read.csv('C:/Users/Renan/Spark_desafio/stroke_data.csv',header='True',inferSchema='True')\n",
    "\n",
    "\n",
    "# Detalhes dos atributos\n",
    "stroke_df.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+----+------------+-------------+------------+-------------+--------------+-----------------+-----+---------------+------+\n",
      "|  0|gender| age|hypertension|heart_disease|ever_married|    work_type|Residence_type|avg_glucose_level|  bmi| smoking_status|stroke|\n",
      "+---+------+----+------------+-------------+------------+-------------+--------------+-----------------+-----+---------------+------+\n",
      "|  1|Female|18.0|           0|            0|          No|      Private|         Urban|            94.19|12.12|         smokes|     1|\n",
      "|  2|  Male|58.0|           1|            0|         Yes|      Private|         Rural|           154.24| 33.7|   never_smoked|     0|\n",
      "|  3|Female|36.0|           0|            0|         Yes|     Govt_job|         Urban|            72.63| 24.7|         smokes|     0|\n",
      "|  4|Female|62.0|           0|            0|         Yes|Self-employed|         Rural|            85.52| 31.2|formerly smoked|     0|\n",
      "|  5|Female|82.0|           0|            0|         Yes|      Private|         Rural|            59.32| 33.2|         smokes|     1|\n",
      "+---+------+----+------------+-------------+------------+-------------+--------------+-----------------+-----+---------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stroke_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67135"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quantidade de registros no arquivo\n",
    "stroke_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Número de colunas no arquivo\n",
    "len(stroke_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|sum(stroke)|\n",
      "+-----------+\n",
      "|      40287|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Número de pacientes que sofreram derrame\n",
    "column_stroke_df = stroke_df.select(\"stroke\")\n",
    "x = column_stroke_df.agg({'stroke' : 'sum'}) #Realizei a soma, pois os que sofreram derrame estão indicados com 1 e os demais com 0\n",
    "x.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26848"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Número de pacientes que não sofreram derrame\n",
    "no_stroke_df = stroke_df[stroke_df.stroke == 0]\n",
    "no_stroke_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataFrame para pacinetes que sofreram derrame\n",
    "positive_stroke_df = stroke_df[stroke_df.stroke == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+----+------------+-------------+------------+-------------+--------------+-----------------+-----+---------------+------+\n",
      "|  0|gender| age|hypertension|heart_disease|ever_married|    work_type|Residence_type|avg_glucose_level|  bmi| smoking_status|stroke|\n",
      "+---+------+----+------------+-------------+------------+-------------+--------------+-----------------+-----+---------------+------+\n",
      "|  1|Female|18.0|           0|            0|          No|      Private|         Urban|            94.19|12.12|         smokes|     1|\n",
      "|  5|Female|82.0|           0|            0|         Yes|      Private|         Rural|            59.32| 33.2|         smokes|     1|\n",
      "|  8|Female|37.0|           0|            0|         Yes|      Private|         Rural|            156.7| 36.9|         smokes|     1|\n",
      "|  9|Female|41.0|           0|            0|         Yes|     Govt_job|         Rural|            64.06| 33.8|         smokes|     1|\n",
      "| 10|Female|70.0|           0|            0|         Yes|Self-employed|         Rural|            76.34| 24.4|formerly smoked|     1|\n",
      "| 11|Female|25.0|           0|            0|          No|      Private|         Urban|            91.15| 28.7|         smokes|     1|\n",
      "| 13|  Male|72.0|           0|            1|         Yes|      Private|         Rural|           235.22| 40.3|formerly smoked|     1|\n",
      "| 14|Female|20.0|           0|            0|          No|      Private|         Rural|           106.47| 33.7|         smokes|     1|\n",
      "| 15|  Male|20.0|           0|            0|          No|      Private|         Urban|           104.78| 20.3|         smokes|     1|\n",
      "| 16|  Male|41.0|           0|            0|         Yes|Self-employed|         Urban|            159.3| 34.6|         smokes|     1|\n",
      "| 17|Female|23.0|           0|            0|          No|      Private|         Urban|           116.95| 23.8|         smokes|     1|\n",
      "| 18|  Male|22.0|           0|            0|          No|Self-employed|         Rural|            72.05| 31.9|         smokes|     1|\n",
      "| 20|Female|44.0|           0|            0|         Yes|Self-employed|         Rural|           135.03| 36.1|         smokes|     1|\n",
      "| 22|  Male|64.0|           1|            0|         Yes|      Private|         Urban|            84.49| 31.2|         smokes|     1|\n",
      "| 23|Female|78.0|           0|            0|         Yes|      Private|         Rural|           235.63| 32.3|         smokes|     1|\n",
      "| 24|Female|79.0|           0|            0|         Yes|      Private|         Urban|           110.85| 24.1|formerly smoked|     1|\n",
      "| 26|  Male|51.0|           1|            0|         Yes|      Private|         Urban|           112.16| 42.5|formerly smoked|     1|\n",
      "| 27|Female|81.0|           0|            0|         Yes|      Private|         Rural|            81.48| 17.5|formerly smoked|     1|\n",
      "| 29|Female|63.0|           1|            0|         Yes|      Private|         Urban|            74.21| 25.8|formerly smoked|     1|\n",
      "| 30|Female|70.0|           0|            1|         Yes|Self-employed|         Rural|           231.88| 28.0|formerly smoked|     1|\n",
      "+---+------+----+------------+-------------+------------+-------------+--------------+-----------------+-----+---------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Criando um DataFrame temporário a partir do \"positive_stroke_df\", para possibilitar fazer consultas SQL com o spark.sql\n",
    "positive_stroke_df.createOrReplaceTempView(\"temporaria_df\")\n",
    "sqlDF = spark.sql(\"SELECT * FROM temporaria_df\")\n",
    "sqlDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilizando consultas SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23711"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quantidade de pacinentes que sofreram derrame e trabalham no setor Privado\n",
    "spark.sql(\"SELECT work_type FROM temporaria_df WHERE work_type = 'Private'\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10807"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quantidade de pacinentes que sofreram derrame e trabalha no setor Privado\n",
    "spark.sql(\"SELECT work_type FROM temporaria_df WHERE work_type = 'Self-employed'\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5164"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quantidade de pacinentes que sofreram derrame e trabalham no governo\n",
    "spark.sql(\"SELECT work_type FROM temporaria_df WHERE work_type = 'Govt_job'\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+\n",
      "|    work_type|work_count|\n",
      "+-------------+----------+\n",
      "|      Private|     23711|\n",
      "|Self-employed|     10807|\n",
      "|     Govt_job|      5164|\n",
      "|     children|       520|\n",
      "| Never_worked|        85|\n",
      "+-------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Agrupando e somando as categorias de pessoas e suas ocupações, que sofreram derrame\n",
    "spark.sql(\"SELECT work_type, count(*) as work_count FROM temporaria_df WHERE stroke == 1 GROUP BY work_type ORDER BY work_count DESC\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+\n",
      "| age|age_count|\n",
      "+----+---------+\n",
      "|79.0|     2916|\n",
      "|78.0|     2279|\n",
      "|80.0|     1858|\n",
      "|81.0|     1738|\n",
      "|82.0|     1427|\n",
      "|77.0|      994|\n",
      "|74.0|      987|\n",
      "|63.0|      942|\n",
      "|76.0|      892|\n",
      "|70.0|      881|\n",
      "|66.0|      848|\n",
      "|75.0|      809|\n",
      "|67.0|      801|\n",
      "|57.0|      775|\n",
      "|73.0|      759|\n",
      "|65.0|      716|\n",
      "|72.0|      709|\n",
      "|68.0|      688|\n",
      "|69.0|      677|\n",
      "|71.0|      667|\n",
      "+----+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Agrupando as incidências de derrame por idade, ordenando da idade de maior para a de menor incidência\n",
    "spark.sql(\"SELECT age, count(*) as age_count FROM temporaria_df WHERE stroke == 1 GROUP BY age ORDER BY age_count DESC\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantidade de pessoas que sofreram derrames após os 50 anos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28938"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"SELECT age FROM temporaria_df WHERE  age > 50.0\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|          avg(bmi)|\n",
      "+------------------+\n",
      "|29.942490629729495|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT AVG(bmi) FROM temporaria_df \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|    work_type|\n",
      "+-------------+\n",
      "| Never_worked|\n",
      "|Self-employed|\n",
      "|      Private|\n",
      "|     children|\n",
      "|     Govt_job|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Tipos de classificações que compõem a coluna \"work_type\", utilizando select.distinct\n",
    "stroke_df.select(\"work_type\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|gender|\n",
      "+------+\n",
      "|Female|\n",
      "| Other|\n",
      "|  Male|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Pergunta 5\n",
    "stroke_df.select(\"gender\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "expression 'temporaria_df.`gender`' is neither present in the group by, nor is it an aggregate function. Add to group by or wrap in first() (or first_value) if you don't care which value you get.;\nSort [work_count#414L DESC NULLS LAST], true\n+- Aggregate [work_type#102], [gender#97, count(1) AS work_count#414L]\n   +- Filter (stroke#107 = 1)\n      +- SubqueryAlias temporaria_df\n         +- Filter (stroke#107 = 1)\n            +- Relation[0#96,gender#97,age#98,hypertension#99,heart_disease#100,ever_married#101,work_type#102,Residence_type#103,avg_glucose_level#104,bmi#105,smoking_status#106,stroke#107] csv\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-d062ef87c37f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#spark.sql(\"SELECT gender, count(*) FROM temporaria_df\").show()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msql\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"SELECT gender, count(*) as work_count FROM temporaria_df WHERE stroke == 1 GROUP BY work_type ORDER BY work_count DESC\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Spark\\spark-3.1.3-bin-hadoop2.7\\python\\pyspark\\sql\\session.py\u001b[0m in \u001b[0;36msql\u001b[1;34m(self, sqlQuery)\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;33m[\u001b[0m\u001b[0mRow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'row1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'row2'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'row3'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    722\u001b[0m         \"\"\"\n\u001b[1;32m--> 723\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jsparkSession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msql\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msqlQuery\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_wrapped\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    724\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    725\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtableName\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Spark\\spark-3.1.3-bin-hadoop2.7\\python\\lib\\py4j-0.10.9-src.zip\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1304\u001b[0m         return_value = get_return_value(\n\u001b[1;32m-> 1305\u001b[1;33m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[0;32m   1306\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1307\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Spark\\spark-3.1.3-bin-hadoop2.7\\python\\pyspark\\sql\\utils.py\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    115\u001b[0m                 \u001b[1;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m                 \u001b[1;31m# JVM exception message.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m                 \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAnalysisException\u001b[0m: expression 'temporaria_df.`gender`' is neither present in the group by, nor is it an aggregate function. Add to group by or wrap in first() (or first_value) if you don't care which value you get.;\nSort [work_count#414L DESC NULLS LAST], true\n+- Aggregate [work_type#102], [gender#97, count(1) AS work_count#414L]\n   +- Filter (stroke#107 = 1)\n      +- SubqueryAlias temporaria_df\n         +- Filter (stroke#107 = 1)\n            +- Relation[0#96,gender#97,age#98,hypertension#99,heart_disease#100,ever_married#101,work_type#102,Residence_type#103,avg_glucose_level#104,bmi#105,smoking_status#106,stroke#107] csv\n"
     ]
    }
   ],
   "source": [
    "#spark.sql(\"SELECT gender, count(*) FROM temporaria_df\").show()\n",
    "spark.sql(\"SELECT gender, count(*) as work_count FROM temporaria_df WHERE stroke == 1 GROUP BY work_type ORDER BY work_count DESC\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criei um novo DF temporário, com todos os pacinetes do estudo, para fazer outras buscas SQL, a partir da pergunta 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+----+------------+-------------+------------+-------------+--------------+-----------------+-----+---------------+------+\n",
      "|  0|gender| age|hypertension|heart_disease|ever_married|    work_type|Residence_type|avg_glucose_level|  bmi| smoking_status|stroke|\n",
      "+---+------+----+------------+-------------+------------+-------------+--------------+-----------------+-----+---------------+------+\n",
      "|  1|Female|18.0|           0|            0|          No|      Private|         Urban|            94.19|12.12|         smokes|     1|\n",
      "|  2|  Male|58.0|           1|            0|         Yes|      Private|         Rural|           154.24| 33.7|   never_smoked|     0|\n",
      "|  3|Female|36.0|           0|            0|         Yes|     Govt_job|         Urban|            72.63| 24.7|         smokes|     0|\n",
      "|  4|Female|62.0|           0|            0|         Yes|Self-employed|         Rural|            85.52| 31.2|formerly smoked|     0|\n",
      "|  5|Female|82.0|           0|            0|         Yes|      Private|         Rural|            59.32| 33.2|         smokes|     1|\n",
      "|  6|Female|82.0|           0|            0|          No|     Govt_job|         Urban|            234.5| 24.0|formerly smoked|     0|\n",
      "|  7|Female|33.0|           0|            0|         Yes|Self-employed|         Urban|           193.42| 29.9|         smokes|     0|\n",
      "|  8|Female|37.0|           0|            0|         Yes|      Private|         Rural|            156.7| 36.9|         smokes|     1|\n",
      "|  9|Female|41.0|           0|            0|         Yes|     Govt_job|         Rural|            64.06| 33.8|         smokes|     1|\n",
      "| 10|Female|70.0|           0|            0|         Yes|Self-employed|         Rural|            76.34| 24.4|formerly smoked|     1|\n",
      "| 11|Female|25.0|           0|            0|          No|      Private|         Urban|            91.15| 28.7|         smokes|     1|\n",
      "| 12|Female|43.0|           1|            0|          No|Self-employed|         Rural|            60.12| 34.2|formerly smoked|     0|\n",
      "| 13|  Male|72.0|           0|            1|         Yes|      Private|         Rural|           235.22| 40.3|formerly smoked|     1|\n",
      "| 14|Female|20.0|           0|            0|          No|      Private|         Rural|           106.47| 33.7|         smokes|     1|\n",
      "| 15|  Male|20.0|           0|            0|          No|      Private|         Urban|           104.78| 20.3|         smokes|     1|\n",
      "| 16|  Male|41.0|           0|            0|         Yes|Self-employed|         Urban|            159.3| 34.6|         smokes|     1|\n",
      "| 17|Female|23.0|           0|            0|          No|      Private|         Urban|           116.95| 23.8|         smokes|     1|\n",
      "| 18|  Male|22.0|           0|            0|          No|Self-employed|         Rural|            72.05| 31.9|         smokes|     1|\n",
      "| 19|  Male|69.0|           0|            0|         Yes|      Private|         Rural|            64.06| 35.1|formerly smoked|     0|\n",
      "| 20|Female|44.0|           0|            0|         Yes|Self-employed|         Rural|           135.03| 36.1|         smokes|     1|\n",
      "+---+------+----+------------+-------------+------------+-------------+--------------+-----------------+-----+---------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#DataFrame para pacinetes que sofreram derrame\n",
    "all_stroke_df = stroke_df\n",
    "\n",
    "#Criando um DataFrame temporário a partir do \"positive_stroke_df\", para possibilitar fazer consultas SQL com o spark.sql\n",
    "\n",
    "all_stroke_df.createOrReplaceTempView(\"temporaria2_df\")\n",
    "sqlDF2 = spark.sql(\"SELECT * FROM temporaria2_df\")\n",
    "sqlDF2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39530"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Proporção do gênero feminino no estudo\n",
    "spark.sql(\"SELECT gender FROM temporaria2_df WHERE gender LIKE 'F%'\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27594"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Proporção do gênero masculino no estudo\n",
    "spark.sql(\"SELECT gender FROM temporaria2_df WHERE gender LIKE 'M%'\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Proporção de outros gêneros no estudo\n",
    "spark.sql(\"SELECT gender FROM temporaria2_df WHERE gender LIKE 'O%'\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pergunta 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Influência da hipertensão na incidência de derrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56118"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Total de pessoas nao-hipertensas\n",
    "a = spark.sql(\"SELECT hypertension FROM temporaria2_df WHERE hypertension == 0 \").count()\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31470"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Total de não hipertensos que sofreram derrame\n",
    "b = spark.sql(\"SELECT hypertension FROM temporaria_df WHERE hypertension == 0 \").count()\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15711536405431412"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Proporção de não hipertensos que sofreram derrame\n",
    "b/a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11017"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Total de pessoas hipertensas\n",
    "c= spark.sql(\"SELECT hypertension FROM temporaria2_df WHERE hypertension == 1 \").count()\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8817"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Total de hipertensos que sofreram derrame\n",
    "d = spark.sql(\"SELECT hypertension FROM temporaria_df WHERE hypertension == 1 \").count()\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8003086139602432"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Proporção de não hipertensos que sofreram derrame\n",
    "d/c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nível médio de glicose para pessoas que, respectivamente, sofreram e não sofreram derrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+\n",
      "|avg(avg_glucose_level)|\n",
      "+----------------------+\n",
      "|    119.95307046938272|\n",
      "+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#SOFREU\n",
    "spark.sql(\"SELECT avg(avg_glucose_level)  FROM temporaria_df\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|      hypertension|\n",
      "+------------------+\n",
      "|113.41439606762462|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#NÃO SOFREU\n",
    "spark.sql(\"SELECT avg(avg_glucose_level) hypertension FROM temporaria2_df\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nível médio de BMI (IMC = índice de massa corpórea) para pessoas que, respectivamente, sofreram e não sofreram derrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|          avg(bmi)|\n",
      "+------------------+\n",
      "|29.942490629729495|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#SOFREU\n",
    "spark.sql(\"SELECT avg(bmi)  FROM temporaria_df\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|     hypertension|\n",
      "+-----------------+\n",
      "|29.16154047813857|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#NÃO SOFREU\n",
    "spark.sql(\"SELECT avg(bmi) hypertension FROM temporaria2_df\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+-----+\n",
      "| age|gender|count|\n",
      "+----+------+-----+\n",
      "| 6.0|Female|  126|\n",
      "| 5.0|Female|  258|\n",
      "|10.0|  Male|  170|\n",
      "|77.0|Female|  856|\n",
      "| 3.0|  Male|  209|\n",
      "|57.0|  Male|  620|\n",
      "|1.16|Female|   24|\n",
      "|66.0|  Male|  509|\n",
      "|81.0|Female| 1319|\n",
      "|11.0|  Male|  167|\n",
      "| 4.0|Female|  182|\n",
      "|1.72|Female|   23|\n",
      "|30.0|Female|  343|\n",
      "|67.0|Female|  600|\n",
      "| 8.0|  Male|  225|\n",
      "|53.0| Other|    2|\n",
      "|0.56|Female|   21|\n",
      "|12.0|Female|  178|\n",
      "| 8.0|Female|  211|\n",
      "|47.0|  Male|  369|\n",
      "+----+------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Exemplo com groupBy\n",
    "stroke_df.groupBy(\"age\", \"gender\").count().show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Previsão da ocorrência de derrame nos pacientes, utilizando Árvore de Decisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- 0: integer (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- age: double (nullable = true)\n",
      " |-- hypertension: integer (nullable = true)\n",
      " |-- heart_disease: integer (nullable = true)\n",
      " |-- ever_married: string (nullable = true)\n",
      " |-- work_type: string (nullable = true)\n",
      " |-- Residence_type: string (nullable = true)\n",
      " |-- avg_glucose_level: double (nullable = true)\n",
      " |-- bmi: double (nullable = true)\n",
      " |-- smoking_status: string (nullable = true)\n",
      " |-- stroke: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stroke_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+----+------------+-------------+------------+-------------+--------------+-----------------+-----+---------------+------+\n",
      "|  0|gender| age|hypertension|heart_disease|ever_married|    work_type|Residence_type|avg_glucose_level|  bmi| smoking_status|stroke|\n",
      "+---+------+----+------------+-------------+------------+-------------+--------------+-----------------+-----+---------------+------+\n",
      "|  1|Female|18.0|           0|            0|          No|      Private|         Urban|            94.19|12.12|         smokes|     1|\n",
      "|  2|  Male|58.0|           1|            0|         Yes|      Private|         Rural|           154.24| 33.7|   never_smoked|     0|\n",
      "|  3|Female|36.0|           0|            0|         Yes|     Govt_job|         Urban|            72.63| 24.7|         smokes|     0|\n",
      "|  4|Female|62.0|           0|            0|         Yes|Self-employed|         Rural|            85.52| 31.2|formerly smoked|     0|\n",
      "|  5|Female|82.0|           0|            0|         Yes|      Private|         Rural|            59.32| 33.2|         smokes|     1|\n",
      "+---+------+----+------------+-------------+------------+-------------+--------------+-----------------+-----+---------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stroke_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecionando as colunas que eu vou usar para a Árvore de Decisão\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "assembler = VectorAssembler(inputCols=['age', 'hypertension', 'heart_disease', 'avg_glucose_level'], outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier_555ccbc5c4a4"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Usando a Árvore de decisão\n",
    "\n",
    "# Em 'labelCol' coloco a coluna que vamos fazer as predições\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "\n",
    "classifier = DecisionTreeClassifier(labelCol='stroke', featuresCol='features')\n",
    "\n",
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizando o pipeline, que é um fluxo de trabalho completo que combina vários algoritmos de aprendizado de máquina\n",
    "#Eles definem os estágios e a ordenação de um processo de apredizagem de máquina\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "pipeline = Pipeline(stages=[assembler, classifier])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separando parte dos dados para treinos e testes\n",
    "\n",
    "train_data, test_data = stroke_df.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando um modelo criado com os dados de treinamento\n",
    "\n",
    "predictStrokedModel = pipeline.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------+-------------+-----------------+---------------+----------+\n",
      "| age|hypertension|heart_disease|avg_glucose_level|  rawPrediction|prediction|\n",
      "+----+------------+-------------+-----------------+---------------+----------+\n",
      "|82.0|           0|            0|            59.32|[1615.0,9714.0]|       1.0|\n",
      "|33.0|           0|            0|           193.42|[3555.0,3052.0]|       0.0|\n",
      "|37.0|           0|            0|            156.7|[4981.0,5342.0]|       1.0|\n",
      "|72.0|           0|            1|           235.22| [835.0,2941.0]|       1.0|\n",
      "|20.0|           0|            0|           104.78|[3555.0,3052.0]|       0.0|\n",
      "+----+------------+-------------+-----------------+---------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Realizando as predições com o modelo criado\n",
    "\n",
    "predictions = predictStrokedModel.transform(test_data)\n",
    "predictions.select('age', 'hypertension', 'heart_disease', 'avg_glucose_level', 'rawPrediction', 'prediction').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6864343958487769"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculando a precisão do modelo criado\n",
    "\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol='stroke', predictionCol='prediction', metricName='accuracy')\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "\n",
    "accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obteve-se uma precisão de 68,6% com o modelo criado, utilizando as colunas referentes à idade, hipertensão, doença cardíaca e nível médio de glicose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adicionando mais variáveis para tentar melhorar a precisão da predição"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Incluindo a variável categórica gênero, transformando o conteúdo dessa coluna em vetores, para ser utilizado na predição\n",
    "\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder\n",
    "\n",
    "\n",
    "#Indexamos os nomes em uma nova coluna\n",
    "gender_indexer = StringIndexer(inputCol='gender', outputCol='genderIndex')\n",
    "\n",
    "#Criamos uma coluna de vetores que será utilizada na predição\n",
    "gender_encoder = OneHotEncoder(inputCol='genderIndex', outputCol='genderVector')\n",
    "\n",
    "\n",
    "#Incluindo a variável categórica gênero, fazendo a mesma transformação para vetores\n",
    "\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder\n",
    "\n",
    "smoke_indexer = StringIndexer(inputCol='smoking_status', outputCol='smokeIndex')\n",
    "smoke_encoder = OneHotEncoder(inputCol='smokeIndex', outputCol='smokeVector')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adicionando as colunas vetorias recém-criadas, smokeVector e genderVector\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "assembler = VectorAssembler(inputCols=['age', 'hypertension', 'heart_disease', 'avg_glucose_level', 'smokeVector', 'genderVector'], outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier_8a283e793eb2"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Usando a Árvore de decisão \n",
    "\n",
    "# Em 'labelCol' coloca a coluna que vamos fazer as predições\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "\n",
    "classifier = DecisionTreeClassifier(labelCol='stroke', featuresCol='features')\n",
    "\n",
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "\n",
    "pipeline = Pipeline(stages=[gender_indexer, gender_encoder, smoke_indexer, smoke_encoder, assembler, classifier])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = stroke_df.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictStrokedModel = pipeline.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------+-------------+-----------------+-------------+------+-------------+---------------+----------+\n",
      "| age|hypertension|heart_disease|avg_glucose_level| genderVector|gender|  smokeVector| smoking_status|prediction|\n",
      "+----+------------+-------------+-----------------+-------------+------+-------------+---------------+----------+\n",
      "|18.0|           0|            0|            94.19|(2,[0],[1.0])|Female|(2,[0],[1.0])|         smokes|       1.0|\n",
      "|41.0|           0|            0|            64.06|(2,[0],[1.0])|Female|(2,[0],[1.0])|         smokes|       1.0|\n",
      "|72.0|           0|            1|           235.22|(2,[1],[1.0])|  Male|(2,[1],[1.0])|formerly smoked|       1.0|\n",
      "|41.0|           0|            0|            159.3|(2,[1],[1.0])|  Male|(2,[0],[1.0])|         smokes|       1.0|\n",
      "|69.0|           0|            0|            64.06|(2,[1],[1.0])|  Male|(2,[1],[1.0])|formerly smoked|       0.0|\n",
      "+----+------------+-------------+-----------------+-------------+------+-------------+---------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = predictStrokedModel.transform(test_data)\n",
    "predictions.select('age', 'hypertension', 'heart_disease', 'avg_glucose_level','genderVector' , 'gender','smokeVector','smoking_status', 'prediction').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8318636678886356"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculando novamente a precisão do nosso modelo, agora adicionada as colunas que referem ao status de fumante e gênero\n",
    "\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol='stroke', predictionCol='prediction', metricName='accuracy')\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notamos um bom aumento na precisão de nossa predição, chegando a casa dos 83,1% de precisão com relação aos casos de pacinetes que sofrerão derrame, com a adição das variáveis fumante e gênero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassificationModel: uid=DecisionTreeClassifier_8a283e793eb2, depth=5, numNodes=19, numClasses=2, numFeatures=8"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Obtendo parâmetros da Árvore de Decisão: Profundidade, número de nós, número de classes, número de features\n",
    "\n",
    "#Colquei 'stages[-1]' porque pegou o ultimo elemento da lista 'predictStrokedModel', como pode ver no print\n",
    "decisionTreeModel = predictStrokedModel.stages[-1]\n",
    "\n",
    "display(decisionTreeModel)\n",
    "\n",
    "#decisionTreeModel.depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Profundidade da Árvore de Decisão\n",
    "decisionTreeModel.depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grau de relevância de cada variável para a incidência de derrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('age', 0.17213452387853628),\n",
       " ('hypertension', 0.0),\n",
       " ('heart_disease', 0.0),\n",
       " ('avg_glucose_level', 0.007431288840423885),\n",
       " ('smokeVector', 0.4879526909808828),\n",
       " ('genderVector', 0.331995578154012)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(assembler.getInputCols(), decisionTreeModel.featureImportances))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pudemos notar que a variável com maior imapacto foi o status de fumante, seguida do gênero e idade. De acordo com nosso modelo, a hipertensão e doenças cardíacas não tiveram influência para o aumento dos casos de derrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DecisionTreeClassificationModel: uid=DecisionTreeClassifier_8a283e793eb2, depth=5, numNodes=19, numClasses=2, numFeatures=8\\n  If (feature 4 in {0.0})\\n   If (feature 5 in {0.0})\\n    Predict: 0.0\\n   Else (feature 5 not in {0.0})\\n    If (feature 0 <= 56.5)\\n     Predict: 0.0\\n    Else (feature 0 > 56.5)\\n     If (feature 0 <= 73.5)\\n      If (feature 3 <= 74.16)\\n       Predict: 0.0\\n      Else (feature 3 > 74.16)\\n       Predict: 1.0\\n     Else (feature 0 > 73.5)\\n      Predict: 1.0\\n  Else (feature 4 not in {0.0})\\n   If (feature 0 <= 66.5)\\n    Predict: 1.0\\n   Else (feature 0 > 66.5)\\n    If (feature 0 <= 73.5)\\n     Predict: 1.0\\n    Else (feature 0 > 73.5)\\n     If (feature 6 in {0.0})\\n      If (feature 3 <= 58.465)\\n       Predict: 0.0\\n      Else (feature 3 > 58.465)\\n       Predict: 1.0\\n     Else (feature 6 not in {0.0})\\n      Predict: 1.0\\n'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decisionTreeModel.toDebugString"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
